"""
æ¨¡å‹æµ‹è¯•è„šæœ¬ - åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹å¹¶è¯„ä¼°
"""
from deletion_model_train import (
    StableLongTailDualModel, ModelConfig, TrainingConfig,
    get_output_path
)
from common_def import *
import argparse


def load_trained_model(model_path, num_features, seq_feature_dim):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    print(f"ğŸ“‚ åŠ è½½æ¨¡å‹: {model_path}")
    

    checkpoint = torch.load(model_path, map_location=DEVICE, weights_only=False)
    config = checkpoint.get('config', {})
    
    # åˆå§‹åŒ–æ¨¡å‹
    model = StableLongTailDualModel(
        num_features=num_features,
        seq_feature_dim=seq_feature_dim,
        hidden_dim=config.get('hidden_dim', 128),
        out_dim=config.get('out_dim', 96),
        temperature=config.get('temperature', 0.8),
        freq_threshold=config.get('freq_threshold', 0.3),
        tail_alpha=0.8,
        ema_decay=config.get('ema_decay', 0.95),
        gate_smoothing=config.get('gate_smoothing', 0.7)
    ).to(DEVICE)
    
    model.load_state_dict(checkpoint['model'], strict=False)
    model.eval()
    
    print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    print(f"   è®­ç»ƒé…ç½®: {config.get('loss_type', 'N/A')}")
    print(f"   æœ€ä½³Epoch: {config.get('best_epoch', 'N/A')}")
    
    return model, config


def main(model_path=None, test_dataset='both'):
    """
    ä¸»æµ‹è¯•å‡½æ•°
    
    Args:
        model_path: æ¨¡å‹è·¯å¾„ï¼Œé»˜è®¤ä½¿ç”¨æœ€ä½³lossæ¨¡å‹
        test_dataset: 'test1', 'test2', 'both'
    """
    print("="*80)
    print("ğŸ§ª DU-AxisCRISP æ¨¡å‹æµ‹è¯•")
    print("="*80)
    
    # åˆå§‹åŒ–é…ç½®
    model_config = ModelConfig()
    train_config = TrainingConfig()
    
    # è®¾ç½®é»˜è®¤æ¨¡å‹è·¯å¾„
    if model_path is None:
        output_path = get_output_path(model_config, train_config)
        model_path = output_path.replace(".pth", "_best_loss.pth")
    
    print(f"\nğŸ“Š æµ‹è¯•é…ç½®:")
    print(f"   è®¾å¤‡: {DEVICE}")
    print(f"   æ¨¡å‹: {model_path}")
    print(f"   æµ‹è¯•é›†: {test_dataset}")
    print(f"   ç‰¹å¾é›†: {train_config.FEATURES}")
    
    # åŠ è½½æ•°æ®
    print(f"\nğŸ“‚ åŠ è½½æ•°æ®...")
    with open(indels_sorted_path, "rb") as f:
        ALL_INDELS = pkl.load(f)
    
    X, y, samples, sequences = load_delete_data(
        filepath=train_file_path, num_samples=1, fractions=True, indel_list=ALL_INDELS
    )
    X = X.loc[:, FEATURE_SETS[train_config.FEATURES]]
    
    # åŠ è½½æ¨¡å‹
    model, config = load_trained_model(model_path, X.shape[1], sequences.shape[1])
    
    # è®¡ç®—å…ˆéªŒ
    prior = compute_prior_stable(y)
    A = make_logit_adjustment(prior, tau=1, device=DEVICE)
    
    # åŠ è½½æµ‹è¯•é›†
    print(f"\nğŸ“Š åŠ è½½æµ‹è¯•é›†...")
    if test_dataset == 'test1':
        test_X, test_y, test_samples, test_sequences = load_delete_data(
            filepath=test_file_path, num_samples=None, fractions=True, indel_list=ALL_INDELS
        )
        test_X = test_X.loc[:, FEATURE_SETS[train_config.FEATURES]]
        print(f"   Test1 æ ·æœ¬æ•°: {len(test_samples)}")
    elif test_dataset == 'test2':
        test_X, test_y, test_samples, test_sequences = load_delete_data_inDelphi(
            filepath=t2_path, num_samples=None, fractions=True, indel_list=ALL_INDELS
        )
        test_X = test_X.loc[:, FEATURE_SETS[train_config.FEATURES]]
        print(f"   Test2 æ ·æœ¬æ•°: {len(test_samples)}")
    else:  # both
        test_X, test_y, test_samples, test_sequences = merge_tests(
            t1_path, t2_path, indel_list=ALL_INDELS, mode="union"
        )
        test_X = test_X.loc[:, FEATURE_SETS[train_config.FEATURES]]
        print(f"   åˆå¹¶æµ‹è¯•é›†æ ·æœ¬æ•°: {len(test_samples)}")
    
    # è¯„ä¼°æ¨¡å‹
    print(f"\n{'='*80}")
    print("ğŸ¯ å¼€å§‹è¯„ä¼°")
    print(f"{'='*80}\n")
    
    test_reg, test_cls = test_model(
        model, test_X, test_y, test_samples, test_sequences, ALL_INDELS, A
    )
    
    # æ‰“å°ç»“æœ
    print(f"\n{'='*80}")
    print("ğŸ“ˆ è¯„ä¼°ç»“æœ")
    print(f"{'='*80}")
    print_results(test_reg, test_cls)
    
    # æ‰“å°å…³é”®æŒ‡æ ‡
    print(f"\n{'='*80}")
    print("ğŸ† å…³é”®æŒ‡æ ‡æ€»ç»“")
    print(f"{'='*80}")
    print(f"   Pearsonç›¸å…³ç³»æ•°: {test_reg['avg_correlation']:.4f}")
    print(f"   KLæ•£åº¦: {test_reg['avg_kl_divergence']:.6f}")
    print(f"   å¹³å‡MSE: {test_reg['avg_mse']:.6f}")
    
    if test_cls and 'thresholds' in test_cls:
        threshold_idx = test_cls['thresholds'].index(0.3) if 0.3 in test_cls['thresholds'] else 0
        print(f"\n   @ é˜ˆå€¼ 0.3:")
        print(f"     MCC: {test_cls['mcc'][threshold_idx]:.4f}")
        print(f"     Precision: {test_cls['precision'][threshold_idx]:.4f}")
        print(f"     Recall: {test_cls['recall'][threshold_idx]:.4f}")
        print(f"     F1-Score: {test_cls['f1_score'][threshold_idx]:.4f}")
    
    print(f"\n{'='*80}")
    print("âœ… æµ‹è¯•å®Œæˆ!")
    print(f"{'='*80}\n")
    
    return test_reg, test_cls


#python deletion_test.py --model output/dual0_freq_v3_stable_WKL0.25_T0.8_KL_Div_freq0.3_v2_testall_best_loss.pth --dataset test1
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='DU-AxisCRISP æ¨¡å‹æµ‹è¯•')
    parser.add_argument('--model', type=str, default=None,
                        help='æ¨¡å‹è·¯å¾„ (é»˜è®¤: best_lossæ¨¡å‹)')
    parser.add_argument('--dataset', type=str, default='both',
                        choices=['test1', 'test2', 'both'],
                        help='æµ‹è¯•æ•°æ®é›†: test1, test2, æˆ– both')
    
    args = parser.parse_args()
    main(model_path=args.model, test_dataset=args.dataset)

