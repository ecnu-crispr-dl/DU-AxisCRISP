"""
æ’å…¥æ¨¡å‹æµ‹è¯•è„šæœ¬ - åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹å¹¶è¯„ä¼°
"""

# ============================================================================
# å¯¼å…¥ä¾èµ–
# ============================================================================
from ins_model_train import (
    TrainingConfig, LossConfig,
    get_output_path, INSERTION_INDELS
)
from models.tcn import AxisTCN
from common_def import *
import argparse


# ============================================================================
# æ¨¡å‹åŠ è½½
# ============================================================================
def load_trained_model(model_path):
    """åŠ è½½è®­ç»ƒå¥½çš„æ’å…¥æ¨¡å‹"""
    print(f"ğŸ“‚ åŠ è½½æ¨¡å‹: {model_path}")
    
    checkpoint = torch.load(model_path, map_location=DEVICE, weights_only=False)
    config = checkpoint.get('config', {})
    
    # åˆå§‹åŒ–AxisTCNæ¨¡å‹ï¼ˆç»“æ„ç®€å•ï¼Œæ— éœ€é…ç½®å‚æ•°ï¼‰
    model = AxisTCN().to(DEVICE)
    
    model.load_state_dict(checkpoint['model'], strict=False)
    model.eval()
    
    print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    print(f"   è®­ç»ƒé…ç½®: {config.get('loss_type', 'N/A')}")
    print(f"   æœ€ä½³Epoch: {config.get('best_epoch', 'N/A')}")
    print(f"   Alpha: {config.get('alpha', 'N/A')}")
    
    return model, config


# ============================================================================
# ä¸»æµ‹è¯•å‡½æ•°
# ============================================================================
def main(model_path=None, test_dataset='test1'):
    """
    ä¸»æµ‹è¯•å‡½æ•°
    
    Args:
        model_path: æ¨¡å‹è·¯å¾„ï¼Œé»˜è®¤ä½¿ç”¨æœ€ä½³lossæ¨¡å‹
        test_dataset: 'test1', 'test2'ï¼ˆæ’å…¥æ¨¡å‹åªåœ¨test1ä¸Šè¯„ä¼°ï¼‰
    """
    print("=" * 80)
    print("ğŸ§ª DU-AxisCRISP æ’å…¥æ¨¡å‹æµ‹è¯•")
    print("=" * 80)
    
    # åˆå§‹åŒ–é…ç½®
    train_config = TrainingConfig()
    loss_config = LossConfig()
    
    # è®¾ç½®é»˜è®¤æ¨¡å‹è·¯å¾„
    if model_path is None:
        output_path = get_output_path(loss_config)
        model_path = output_path.replace(".pth", "_best_loss.pth")
    
    print(f"\nğŸ“Š æµ‹è¯•é…ç½®:")
    print(f"   è®¾å¤‡: {DEVICE}")
    print(f"   æ¨¡å‹: {model_path}")
    print(f"   æµ‹è¯•é›†: {test_dataset}")
    print(f"   ç‰¹å¾é›†: {train_config.FEATURES}")
    
    # åŠ è½½æ¨¡å‹
    model, config = load_trained_model(model_path)
    
    # åŠ è½½æµ‹è¯•é›†
    print(f"\nğŸ“Š åŠ è½½æµ‹è¯•é›†...")
    if test_dataset == 'test1':
        test_X, test_y, test_samples, test_sequences = load_insert_data(
            filepath=test_file_path, 
            num_samples=None, 
            fractions=True, 
            indel_list=INSERTION_INDELS
        )
        print(f"   Test1 æ ·æœ¬æ•°: {len(test_samples)}")
    elif test_dataset == 'test2':
        test_X, test_y, test_samples, test_sequences = load_insert_data(
            filepath=t2_path, 
            num_samples=None, 
            fractions=True, 
            indel_list=INSERTION_INDELS
        )
        print(f"   Test2 æ ·æœ¬æ•°: {len(test_samples)}")
    else:
        raise ValueError(f"Unsupported test_dataset: {test_dataset}. Use 'test1' or 'test2'.")
    
    test_X = test_X.loc[:, FEATURE_SETS[train_config.FEATURES]]
    
    # è®¡ç®—å…ˆéªŒ
    prior = compute_prior_stable(test_y)
    A = make_logit_adjustment(prior, tau=1, device=DEVICE)
    
    # è¯„ä¼°æ¨¡å‹
    print(f"\n{'=' * 80}")
    print("ğŸ¯ å¼€å§‹è¯„ä¼°")
    print(f"{'=' * 80}\n")
    
    test_reg, test_cls = test_model(
        model, test_X, test_y, test_samples, test_sequences, INSERTION_INDELS, A
    )
    
    # æ‰“å°ç»“æœ
    print(f"\n{'=' * 80}")
    print("ğŸ“ˆ è¯„ä¼°ç»“æœ")
    print(f"{'=' * 80}")
    print_results(test_reg, test_cls)
    
    # æ‰“å°å…³é”®æŒ‡æ ‡
    print(f"\n{'=' * 80}")
    print("ğŸ† å…³é”®æŒ‡æ ‡æ€»ç»“")
    print(f"{'=' * 80}")
    print(f"   Pearsonç›¸å…³ç³»æ•°: {test_reg['avg_correlation']:.4f}")
    print(f"   KLæ•£åº¦: {test_reg['avg_kl_divergence']:.6f}")
    print(f"   å¹³å‡MSE: {test_reg['avg_mse']:.6f}")
    
    if test_cls and 'thresholds' in test_cls:
        threshold_idx = test_cls['thresholds'].index(0.3) if 0.3 in test_cls['thresholds'] else 0
        print(f"\n   @ é˜ˆå€¼ 0.3:")
        print(f"     MCC: {test_cls['mcc'][threshold_idx]:.4f}")
        print(f"     Precision: {test_cls['precision'][threshold_idx]:.4f}")
        print(f"     Recall: {test_cls['recall'][threshold_idx]:.4f}")
        print(f"     F1-Score: {test_cls['f1_score'][threshold_idx]:.4f}")
    
    print(f"\n{'=' * 80}")
    print("âœ… æµ‹è¯•å®Œæˆ!")
    print(f"{'=' * 80}\n")
    
    return test_reg, test_cls


# ============================================================================
# å‘½ä»¤è¡Œå…¥å£
# ============================================================================
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='DU-AxisCRISP æ’å…¥æ¨¡å‹æµ‹è¯•')
    parser.add_argument('--model', type=str, default=None,
                        help='æ¨¡å‹è·¯å¾„ (é»˜è®¤: best_lossæ¨¡å‹)')
    parser.add_argument('--dataset', type=str, default='test1',
                        choices=['test1', 'test2'],
                        help='æµ‹è¯•æ•°æ®é›†: test1 æˆ– test2')
    
    args = parser.parse_args()
    main(model_path=args.model, test_dataset=args.dataset)

